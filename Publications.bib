
@incollection{Bian2019,
  title = {An Accurate {{LSTM}} Based Video Heart Rate Estimation Method},
  booktitle = {Chinese Conference on Pattern Recognition and Computer Vision ({{PRCV}})},
  author = {Bian, Mingyun and Peng, Bo and Wang, Wei and Dong, Jing},
  year = {2019},
  pages = {409--417},
  doi = {10.1007/978-3-030-31726-3_35},
  abstract = {Pulse signal is an effective indicator to reflect the physiological and physical state of the human body. There are many heart rate estimation methods in videos and most of them manually design algorithm to modeling noise signal, which is not enough to represent the actual distribution of noise. In this paper, we propose to train a two-layer LSTM to estimate pulse signals because long short-term memory (LSTM) can preserve useful signals by filtering out noise signals upon data-driven. In order to overcome the problem of insufficient heart rate public database, we propose to use quantities of synthetic signals which are generated by the algorithm we designed to pre-train the model and pure periodic signals are filtered from LSTM to calculate the heart rate. Experiential results on the public-domain database show the effectiveness of our proposed method that can be a reference for the heart rate estimation.},
  copyright = {All rights reserved}
}

@incollection{Dong2009,
  title = {Multi-Class Blind Steganalysis Based on Image Run-Length Analysis},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2009},
  volume = {5703 LNCS},
  pages = {199--210},
  issn = {03029743},
  doi = {10.1007/978-3-642-03688-0_19},
  abstract = {In this paper, we investigate our previously developed run-length based features for multi-class blind image steganalysis. We construct a Support Vector Machine classifier for multi-class recognition for both spatial and frequency domain based steganographic algorithms. We also study hierarchical and non-hierarchical multi-class schemes and compare their performance for steganalysis. Experimental results demonstrate that our approach is able to classify different stego images according to their embedding techniques based on appropriate supervised learning. It is also shown that the hierarchical scheme performs better in our experiments. \textcopyright{} 2009 Springer.},
  copyright = {All rights reserved},
  isbn = {3-642-03687-2},
  keywords = {Blind steganalysis,Image steganalysis,Multi-class,Run-length analysis}
}

@incollection{Dong2009a,
  title = {Run-Length and Edge Statistics Based Approach for Image Splicing Detection},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Dong, Jing and Wang, Wei and Tan, Tieniu and Shi, Yun Q.},
  year = {2009},
  volume = {5450 LNCS},
  pages = {76--87},
  issn = {03029743},
  doi = {10.1007/978-3-642-04438-0_7},
  abstract = {In this paper, a simple but efficient approach for blind image splicing detection is proposed. Image splicing is a common and fundamental operation used for image forgery. The detection of image splicing is a preliminary but desirable study for image forensics. Passive detection approaches of image splicing are usually regarded as pattern recognition problems based on features which are sensitive to splicing. In the proposed approach, we analyze the discontinuity of image pixel correlation and coherency caused by splicing in terms of image run-length representation and sharp image characteristics. The statistical features extracted from image run-length representation and image edge statistics are used for splicing detection. The support vector machine (SVM) is used as the classifier. Our experimental results demonstrate that the two proposed features outperform existing ones both in detection accuracy and computational complexity. \textcopyright{} Springer-Verlag Berlin Heidelberg 2009.},
  copyright = {All rights reserved},
  isbn = {3-642-04437-9},
  keywords = {Characteristic functions,Edge detection,Image splicing,Run-length,Support vector machine (SVM)}
}

@inproceedings{Dong2013,
  title = {{{CASIA}} Image Tampering Detection Evaluation Database},
  booktitle = {2013 {{IEEE}} China Summit and International Conference on Signal and Information Processing, {{ChinaSIP}} 2013 - Proceedings},
  author = {Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2013},
  month = jul,
  pages = {422--426},
  publisher = {{IEEE}},
  doi = {10.1109/ChinaSIP.2013.6625374},
  abstract = {Image forensics has now raised the anxiety of justice as increasing cases of abusing tampered images in newspapers and court for evidence are reported recently. With the goal of verifying image content authenticity, passive-blind image tampering detection is called for. More realistic open benchmark databases are also needed to assist the techniques. Recently, we collect a natural color image database with realistic tampering operations. The database is made publicly available for researchers to compare and evaluate their proposed tampering detection techniques. We call this database CASI-A Image Tampering Detection Evaluation Database. We describe the purpose, the design criterion, the organization and self-evaluation of this database in this paper. \textcopyright{} 2013 IEEE.},
  copyright = {All rights reserved},
  isbn = {978-1-4799-1043-4},
  keywords = {Algorithm Evaluation,Database,Image Forensics,Tampering Detection}
}

@article{dong2017,
  title = {Recent Advances in Image Steganalysis},
  author = {Dong, Jing and Qian, Yinlong and Wang, Wei},
  year = {2017},
  volume = {06},
  pages = {131--138},
  publisher = {{Scientific Research Publishing}},
  issn = {2325-6753},
  doi = {10.12677/jisp.2017.63016},
  copyright = {All rights reserved},
  journal = {Journal of Image and Signal Processing},
  number = {03}
}

@article{Hao2016,
  title = {What Is the Best Practice for {{CNNs}} Applied to Visual Instance Retrieval?},
  author = {Hao, Jiedong and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2016},
  month = nov,
  abstract = {Previous work has shown that feature maps of deep convolutional neural networks (CNNs) can be interpreted as feature representation of a particular image region. Features aggregated from these feature maps have been exploited for image retrieval tasks and achieved state-of-the-art performances in recent years. The key to the success of such methods is the feature representation. However, the different factors that impact the effectiveness of features are still not explored thoroughly. There are much less discussion about the best combination of them. The main contribution of our paper is the thorough evaluations of the various factors that affect the discriminative ability of the features extracted from CNNs. Based on the evaluation results, we also identify the best choices for different factors and propose a new multi-scale image feature representation method to encode the image effectively. Finally, we show that the proposed method generalises well and outperforms the state-of-the-art methods on four typical datasets used for visual instance retrieval.},
  archivePrefix = {arXiv},
  arxivid = {1611.01640},
  copyright = {All rights reserved},
  eprint = {1611.01640},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1611.01640}
}

@inproceedings{Hao2017,
  title = {{{MFC}}: {{A}} Multi-Scale Fully Convolutional Approach for Visual Instance Retrieval},
  booktitle = {2017 {{IEEE}} International Conference on Multimedia and Expo Workshops, {{ICMEW}} 2017},
  author = {Hao, Jiedong and Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2017},
  month = jul,
  pages = {513--518},
  publisher = {{IEEE}},
  doi = {10.1109/ICMEW.2017.8026302},
  abstract = {Previous work has shown that feature maps of deep convolutional neural networks (CNNs) can be interpreted as feature representation of an image. Image features aggregated from these feature maps have achieved steady progress in terms of performances on visual instance retrieval tasks in recent years. The key to the success of such methods is feature representation. In this paper, we study how to represent an image using discriminative features. We demonstrate first that image size is an important factor which affects the performance of instance retrieval but has not been thoroughly discussed in previous work. Based on experimental evaluations, we propose a multi-scale fully convolutional (MFC) approach to encode the image efficiently and effectively. The proposed method is simple to implement, which does not employ sophisticated post-processing techniques such as query expansion, yet shows promising results on four public datasets.},
  copyright = {All rights reserved},
  isbn = {978-1-5386-0560-8},
  keywords = {Fully Convolutional Neural Network,Image Resizing Strategy,Multi-scale Representation,Visual Instance Retrieval}
}

@inproceedings{Hao2018,
  title = {{{DeepFirearm}}: {{Learning}} Discriminative Feature Representation for Fine-Grained Firearm Retrieval},
  booktitle = {Proceedings - International Conference on Pattern Recognition},
  author = {Hao, Jiedong and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2018},
  month = aug,
  volume = {2018-Augus},
  pages = {3335--3340},
  publisher = {{IEEE}},
  issn = {10514651},
  doi = {10.1109/ICPR.2018.8545529},
  abstract = {There are great demands for automatically regulating inappropriate appearance of shocking firearm images in social media or identifying firearm types in forensics. Image retrieval techniques have great potential to solve these problems. To facilitate research in this area, we introduce Firearm 14k, a large dataset consisting of over 14,000 images in 167 categories. It can be used for both fine-grained recognition and retrieval of firearm images. Recent advances in image retrieval are mainly driven by fine-tuning state-of-the-art convolutional neural networks for retrieval task. The conventional single margin contrastive loss, known for its simplicity and good performance, has been widely used. We find that it performs poorly on the Firearm 14k dataset due to: (1) Loss contributed by positive and negative image pairs is unbalanced during training process. (2) A huge domain gap exists between this dataset and ImageNet. We propose to deal with the unbalanced loss by employing a double margin contrastive loss. We tackle the domain gap issue with a two-stage training strategy, where we first fine-tune the network for classification, and then fine-tune it for retrieval. Experimental results show that our approach outperforms the conventional single margin approach by a large margin (up to 88.5\% relative improvement) and even surpasses the strong triplet-loss-based approach.},
  archivePrefix = {arXiv},
  arxivid = {1806.02984},
  copyright = {All rights reserved},
  eprint = {1806.02984},
  eprinttype = {arxiv},
  isbn = {978-1-5386-3788-3}
}

@article{He2019,
  title = {A New Ensemble Method for Concessively Targeted Multi-Model Attack},
  author = {He, Ziwen and Wang, Wei and Xuan, Xinsheng and Dong, Jing and Tan, Tieniu},
  year = {2019},
  month = dec,
  abstract = {It is well known that deep learning models are vulnerable to adversarial examples crafted by maliciously adding perturbations to original inputs. There are two types of attacks: targeted attack and non-targeted attack, and most researchers often pay more attention to the targeted adversarial examples. However, targeted attack has a low success rate, especially when aiming at a robust model or under a black-box attack protocol. In this case, non-targeted attack is the last chance to disable AI systems. Thus, in this paper, we propose a new attack mechanism which performs the non-targeted attack when the targeted attack fails. Besides, we aim to generate a single adversarial sample for different deployed models of the same task, e.g. image classification models. Hence, for this practical application, we focus on attacking ensemble models by dividing them into two groups: easy-to-attack and robust models. We alternately attack these two groups of models in the non-targeted or targeted manner. We name it a bagging and stacking ensemble (BAST) attack. The BAST attack can generate an adversarial sample that fails multiple models simultaneously. Some of the models classify the adversarial sample as a target label, and other models which are not attacked successfully may give wrong labels at least. The experimental results show that the proposed BAST attack outperforms the state-of-the-art attack methods on the new defined criterion that considers both targeted and non-targeted attack performance.},
  archivePrefix = {arXiv},
  arxivid = {1912.10833},
  copyright = {All rights reserved},
  eprint = {1912.10833},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1912.10833}
}

@article{pan2019new,
  title = {A New Fast Search Algorithm for Exact K-Nearest Neighbors Based on Optimal Triangle-Inequality-Based Check Strategy},
  author = {Pan, Yiwei and Pan, Zhibin and Wang, Yikun and Wang, Wei},
  year = {2020},
  month = oct,
  volume = {189},
  pages = {105088},
  publisher = {{Elsevier}},
  issn = {09507051},
  doi = {10.1016/j.knosys.2019.105088},
  abstract = {The k-nearest neighbor (KNN) algorithm has been widely used in pattern recognition, regression, outlier detection and other data mining areas. However, it suffers from the large distance computation cost, especially when dealing with big data applications. In this paper, we propose a new fast search (FS) algorithm for exact k-nearest neighbors based on optimal triangle-inequality-based (OTI) check strategy. During the procedure of searching exact k-nearest neighbors for any query, the OTI check strategy can eliminate more redundant distance computations for the instances located in the marginal area of neighboring clusters compared with the original TI check strategy. Considering the large space complexity and extra time complexity of OTI, we also propose an efficient optimal triangle-inequality-based (EOTI) check strategy. The experimental results demonstrate that our proposed two algorithms (OTI and EOTI) achieve the best performance compared with other related KNN fast search algorithms, especially in the case of dealing with high-dimensional datasets.},
  copyright = {All rights reserved},
  journal = {Knowledge-Based Systems},
  keywords = {Clustering,Exact k-nearest neighbors,Fast search algorithm,Optimal check strategy,Triangle inequality}
}

@inproceedings{Peng2015,
  title = {Detection of Computer Generated Faces in Videos Based on Pulse Signal},
  booktitle = {2015 {{IEEE}} China Summit and International Conference on Signal and Information Processing, {{ChinaSIP}} 2015 - Proceedings},
  author = {Peng, Bo and Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2015},
  month = jul,
  pages = {841--845},
  publisher = {{IEEE}},
  doi = {10.1109/ChinaSIP.2015.7230523},
  abstract = {The rapid development in the field of computer graphics (CG) makes it quite easy to create photo-realistic images and videos. This brings forward an emergent requirement for techniques that can distinguish CG from real contents. In this paper, we propose a method that leverages human pulse signal to distinguish between CG and real videos that include human faces. We use a robust tracking method to locate a patch of skin on the face. Then, a chrominance-based algorithm is employed to robustly extract pulse signal. By checking the frequency waveform of the extracted pulse signal, we can tell CG and real videos apart. The experiment shows encouraging results, which demonstrate the efficiency of our method.},
  copyright = {All rights reserved},
  isbn = {978-1-4799-1948-2},
  keywords = {CG characters,pulse detection,Video forensics}
}

@inproceedings{Peng2015b,
  title = {Improved {{3D}} Lighting Environment Estimation for Image Forgery Detection},
  booktitle = {2015 {{IEEE}} International Workshop on Information Forensics and Security, {{WIFS}} 2015 - Proceedings},
  author = {Peng, Bo and Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2015},
  month = nov,
  pages = {1--6},
  publisher = {{IEEE}},
  doi = {10.1109/WIFS.2015.7368587},
  abstract = {3D lighting environment is an important clue in an image that can be used for image forgery detection. Existing forensic methods exploring lighting environment consistency are based on many assumptions, among which convexity and constant reflectance of the surface are two critical ones. In this paper, we propose an improved 3D lighting environment estimation method based on a more general surface reflection model. We relax the two assumptions by incorporating the local geometry and texture information into our position dependent reflection model. The proposed model is more realistic for objects like human faces which are non-convex and textured. Experiments show that the proposed method can achieve improved lighting environment estimation accuracy compared to the previous method and has better forgery detection efficacy.},
  copyright = {All rights reserved},
  isbn = {978-1-4673-6802-5}
}

@inproceedings{Peng2016,
  title = {Automatic Detection of {{3D}} Lighting Inconsistencies via a Facial Landmark Based Morphable Model},
  booktitle = {Proceedings - International Conference on Image Processing, {{ICIP}}},
  author = {Peng, Bo and Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2016},
  month = sep,
  volume = {2016-Augus},
  pages = {3932--3936},
  publisher = {{IEEE}},
  issn = {15224880},
  doi = {10.1109/ICIP.2016.7533097},
  abstract = {Existing 3D lighting consistency based forensic methods have some practical problems. They usually require additional images and human labor to reconstruct the 3D face model for lighting estimation, and furthermore, they cannot deal with expressional faces effectively. These drawbacks make them unusable in many practical cases. In this paper, we propose a more practical 3D lighting based forensic method by incorporating a facial landmark based 3D morphable model to efficiently fit the face shape. We also introduce a residual error based algorithm to automatically exclude outliers in lighting estimation. Our proposed method is fully automatic and very efficient compared to previous ones. Also, it does not depend on additional images and has better performance for expressional faces. Experiments on a realistic face dataset with variational lighting conditions indicate the efficacy and superiority of our method.},
  copyright = {All rights reserved},
  isbn = {978-1-4673-9961-6},
  keywords = {3D morphable model,Face splicing,Image forensics,Lighting consistency}
}

@inproceedings{Peng2017a,
  title = {Position Determines Perspective: {{Investigating}} Perspective Distortion for Image Forensics of Faces},
  booktitle = {{{IEEE}} Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
  author = {Peng, Bo and Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2017},
  month = jul,
  volume = {2017-July},
  pages = {1813--1821},
  publisher = {{IEEE}},
  issn = {21607516},
  doi = {10.1109/CVPRW.2017.227},
  abstract = {This paper points out a new telltale trace - the characteristic of perspective distortion (CPD), for the image forensics of faces. The perspective distortion is determined by the position of image shooting, and it is often overlooked when creating a forgery, which results in the inconsistency between the claimed camera parameters and the CPD in the face image. To investigate this consistency problem, we cast it to the consistency between the claimed camera intrinsic parameters and the estimated ones from the CPD. Our parameter estimation approach is based on geometric observations that are related to CPD, like facial landmarks and contours. We analyze the estimation uncertainty caused by indeterminacy of observation to obtain a more reliable forensic decision. Experiments on synthetic datasets and real forgery examples demonstrate the effectiveness of the proposed method.},
  copyright = {All rights reserved},
  isbn = {978-1-5386-0733-6}
}

@article{Peng2017b,
  title = {Optimized {{3D}} Lighting Environment Estimation for Image Forgery Detection},
  author = {Peng, Bo and Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2017},
  month = feb,
  volume = {12},
  pages = {479--494},
  publisher = {{IEEE}},
  issn = {15566013},
  doi = {10.1109/TIFS.2016.2623589},
  abstract = {Image forgery is becoming a growing threat to information credibility. Among all kinds of image forgeries, photographic composites of human faces have very serious impacts. To combat this kind of forgery, some forensic methods propose to estimate the 3D lighting environments from different faces and investigate the consistency between them. Although they are very effective, existing 3D lighting-based forensic methods are limited by many simplifying assumptions about the surface reflection model, among which convexity and constant reflectance are two critical ones. In this paper, we propose an optimized 3D lighting estimation method by incorporating a more general surface reflection model. In this model, we relax the convexity and constant reflectance assumptions by taking the occlusion geometry and surface texture information into consideration. The proposed reflection model is more general and accurate; hence, it can achieve better lighting estimation accuracy and more reliable discrimination performance. Comprehensive experiments on both synthetic and real data sets validate the correctness and efficacy of the proposed method. Comparisons with two existing 3D lighting-based forensic methods also demonstrate the superiority of the proposed method for detecting face splicing.},
  copyright = {All rights reserved},
  journal = {IEEE Transactions on Information Forensics and Security},
  keywords = {Composite detection,Human faces,Image forensics,Lighting estimation},
  number = {2}
}

@article{Peng2018,
  title = {Image Forensics Based on Planar Contact Constraints of {{3D}} Objects},
  author = {Peng, Bo and Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2018},
  month = feb,
  volume = {13},
  pages = {377--392},
  publisher = {{IEEE}},
  issn = {15566013},
  doi = {10.1109/TIFS.2017.2752728},
  abstract = {Standing objects on planar surfaces are common to see in images, e.g., people on the ground. For most objects to stay stable on the plane, planar contact is a necessary requirement. However, 2D image splicing usually disregards this physical constraint of 3D world, leading to a potential artifact of object not attached to the plane. This paper is the first attempt to use the contact constraint of standing objects as a new clue for image forensics. Accordingly, we propose a novel approach to first reconstruct the 3D poses of standing objects and their supporting plane and then measure the contact conditions for splicing detection. To tackle the problem of unknown object shape for pose estimation, we effectively employ the prior knowledge of 3D morphable model to simultaneously estimate both shape and pose parameters by fitting to image observations. The 3D normal orientation of the supporting plane is estimated given its vanishing line. Dealing with uncertainty factors in estimations, we approximate a distribution of estimates using sampling strategies and then make the final decision. Particularly, we focused our method on the important scenario of human figure splicing detection, and comprehensive experiments on multiple data sets and typical images proved the encouraging effectiveness of the new forensic clue and the proposed approach.},
  copyright = {All rights reserved},
  journal = {IEEE Transactions on Information Forensics and Security},
  keywords = {3D morphable model,contact constraint,Image forensics,splicing detection},
  number = {2}
}

@inproceedings{Qian2015,
  title = {Deep Learning for Steganalysis via Convolutional Neural Networks},
  booktitle = {Media Watermarking, Security, and Forensics 2015},
  author = {Qian, Yinlong and Dong, Jing and Wang, Wei and Tan, Tieniu},
  editor = {Alattar, Adnan M. and Memon, Nasir D. and Heitzenrater, Chad D.},
  year = {2015},
  month = mar,
  volume = {9409},
  pages = {94090J},
  issn = {1996756X},
  doi = {10.1117/12.2083479},
  abstract = {\textcopyright{} 2015 SPIE. Current work on steganalysis for digital images is focused on the construction of complex handcrafted features. This paper proposes a new paradigm for steganalysis to learn features automatically via deep learning models. We novelly propose a customized Convolutional Neural Network for steganalysis. The proposed model can capture the complex dependencies that are useful for steganalysis. Compared with existing schemes, this model can automatically learn feature representations with several convolutional layers. The feature extraction and classification steps are unified under a single architecture, which means the guidance of classification can be used during the feature extraction step. We demonstrate the effectiveness of the proposed model on three state-of-theart spatial domain steganographic algorithms - HUGO, WOW, and S-UNIWARD. Compared to the Spatial Rich Model (SRM), our model achieves comparable performance on BOSSbase and the realistic and large ImageNet database.},
  copyright = {All rights reserved},
  isbn = {978-1-62841-499-8}
}

@inproceedings{Qian2016,
  title = {Learning and Transferring Representations for Image Steganalysis Using Convolutional Neural Network},
  booktitle = {Proceedings - International Conference on Image Processing, {{ICIP}}},
  author = {Qian, Yinlong and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2016},
  month = sep,
  volume = {2016-Augus},
  pages = {2752--2756},
  publisher = {{IEEE}},
  issn = {15224880},
  doi = {10.1109/ICIP.2016.7532860},
  abstract = {The major challenge of machine learning based image steganalysis lies in obtaining powerful feature representations. Recently, Qian et al. have shown that Convolutional Neural Network (CNN) is effective for learning features automatically for steganalysis. In this paper, we follow up this new paradigm in steganalysis, and propose a framework based on transfer learning to help the training of CNN for steganalysis, hence to achieve a better performance. We show that feature representations learned with a pre-trained CNN for detecting a steganographic algorithm with a high payload can be efficiently transferred to improve the learning of features for detecting the same steganographic algorithm with a low pay-load. By detecting representative WOW and S-UNIWARD steganographic algorithms, we demonstrate that the proposed scheme is effective in improving the feature learning in CNN models for steganalysis.},
  copyright = {All rights reserved},
  isbn = {978-1-4673-9961-6}
}

@incollection{Qian2016b,
  title = {Learning Representations for Steganalysis from Regularized {{CNN}} Model with Auxiliary Tasks},
  booktitle = {Lecture Notes in Electrical Engineering},
  author = {Qian, Yinlong and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2016},
  volume = {386},
  pages = {629--637},
  publisher = {{Springer Verlag}},
  issn = {18761119},
  doi = {10.1007/978-3-662-49831-6_64},
  abstract = {The key challenge of steganalysis is to construct effective feature representations. Traditional steganalysis systems rely on hand-designed feature extractors. Recently, some efforts have been put toward learning representations automatically using deep models. In this paper, we propose a new CNN based framework for steganalysis based on the concept of incorporating prior knowledge fromauxiliary tasks via transfer learning to regularize the CNNmodel for learning better representations. The auxiliary tasks are generated by computing features that capture global image statisticswhich are hard to be seized by the CNNnetwork structure. By detecting representative modern embedding methods, we demonstrate that the proposed method is effective in improving the feature learning in CNN models.},
  copyright = {All rights reserved},
  isbn = {978-3-662-49829-3}
}

@article{Qian2018a,
  title = {Feature Learning for Steganalysis Using Convolutional Neural Networks},
  author = {Qian, Yinlong and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2018},
  month = aug,
  volume = {77},
  pages = {19633--19657},
  publisher = {{Springer US}},
  issn = {15737721},
  doi = {10.1007/s11042-017-5326-1},
  abstract = {Traditional steganalysis methods usually rely on handcrafted features. However, with the rapid development of advanced steganography, manual design of complex features has become increasingly difficult. In this paper, we propose a new paradigm for steganalysis based on the concept of feature learning. In our method, Convolutional Neural Network (CNN) is used to automatically learn features for steganalysis. To make CNN work better for steganalysis, we incorporate domain knowledge of steganalysis (i.e. enhancing stego noise and exploiting nearby dependencies) when designing the CNN architectures. We further propose to use model combination to boost the performance of CNN based method. Additionally, a cropping strategy is proposed to enable the CNN based model to deal with arbitrary input image sizes. We demonstrate the effectiveness of the proposed method against state-of-the-art spatial domain steganographic algorithms such as HUGO, WOW, S-UNIWARD, MiPOD, and HILL-CMD. To help understand the learned features from CNN, we provide visualizations of the learned filters and feature maps. Finally, we also provide quantitative analysis of the learned features from convolutional layers.},
  copyright = {All rights reserved},
  journal = {Multimedia Tools and Applications},
  keywords = {Convolutional neural networks,Deep learning,Feature learning,Steganalysis,Steganography},
  number = {15}
}

@incollection{Ri2017,
  title = {High Capacity Reversible Data Hiding with Contrast Enhancement},
  booktitle = {Communications in Computer and Information Science},
  author = {Ri, Yonggwon and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2017},
  volume = {772},
  pages = {284--294},
  issn = {18650929},
  doi = {10.1007/978-981-10-7302-1_24},
  abstract = {Reversible data hiding aims at recovering exactly the cover image from the marked image after extracting the hidden data. Reversible data hiding with contrast enhancement proposed by Wu et al. achieved a good effect in improving visual quality with considerable embedding capacity while PSNR of the marked image is relatively low. In contrast, Prediction error based reversible data hiding does not reveal obvious change of visual quality while keeping high embedding capacity and PSNR. In this paper, we propose a novel reversible data hiding method with contrast enhancement based on the combination property of the above two methods.},
  copyright = {All rights reserved},
  isbn = {978-981-10-7301-4},
  keywords = {Contrast enhancement,Prediction error,Reversible data hiding,Watermarking}
}

@incollection{Ri2018,
  title = {Adaptive Histogram Shifting Based Reversible Data Hiding},
  booktitle = {Smart Innovation, Systems and Technologies},
  author = {Ri, Yonggwon and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2018},
  volume = {82},
  pages = {42--50},
  issn = {21903026},
  doi = {10.1007/978-3-319-63859-1_6},
  abstract = {Reversible data hiding (RDH) is a special kind of data hiding technique which can exactly recover the cover image from the stego image after extracting the hidden data. Recently, Wu et al. proposed a novel RDH method with contrast enhancement (RDH-CE). RDH-CE achieved a good effect in improving visual quality especially for poorly illustrated images. In Wu's method, however, the PSNR of stego image is relatively low and embedding performance is largely influenced by the histogram distribution of cover image. Since PSNR is still considered as one of the most important metrics for evaluating the RDH performance, this paper presents a reliable RDH method based on adaptive histogram shifting for gray-scale images to improve the PSNR of stego image while maintaining the good effect of the contrast enhancement obtained by RDH-CE.},
  copyright = {All rights reserved},
  isbn = {978-3-319-63858-4},
  keywords = {Contrast enhancement,Histogram modification,Location map,PSNR,Reversible data hiding}
}

@incollection{Shi2018,
  title = {{{SSGAN}}: {{Secure}} Steganography Based on Generative Adversarial Networks},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Shi, Haichao and Dong, Jing and Wang, Wei and Qian, Yinlong and Zhang, Xiaoyu},
  year = {2018},
  volume = {10735 LNCS},
  pages = {534--544},
  issn = {16113349},
  doi = {10.1007/978-3-319-77380-3_51},
  abstract = {In this paper, a novel strategy of Secure Steganography based on Generative Adversarial Networks is proposed to generate suitable and secure covers for steganography. The proposed architecture has one generative network, and two discriminative networks. The generative network mainly evaluates the visual quality of the generated images for steganography, and the discriminative networks are utilized to assess their suitableness for information hiding. Different from the existing work which adopts Deep Convolutional Generative Adversarial Networks, we utilize another form of generative adversarial networks. By using this new form of generative adversarial networks, significant improvements are made on the convergence speed, the training stability and the image quality. Furthermore, a sophisticated steganalysis network is reconstructed for the discriminative network, and the network can better evaluate the performance of the generated images. Numerous experiments are conducted on the publicly available datasets to demonstrate the effectiveness and robustness of the proposed method.},
  archivePrefix = {arXiv},
  arxivid = {1707.01613},
  copyright = {All rights reserved},
  eprint = {1707.01613},
  eprinttype = {arxiv},
  isbn = {978-3-319-77379-7},
  keywords = {Generative adversarial networks,Steganalysis,Steganography}
}

@inproceedings{Wang2009,
  title = {Effective Image Splicing Detection Based on Image Chroma},
  booktitle = {Proceedings - International Conference on Image Processing, {{ICIP}}},
  author = {Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2009},
  month = nov,
  pages = {1257--1260},
  publisher = {{IEEE}},
  issn = {15224880},
  doi = {10.1109/ICIP.2009.5413549},
  abstract = {A color image splicing detection method based on gray level co-occurrence matrix (GLCM) of thresholded edge image of image chroma is proposed in this paper. Edge images are generated by subtracting horizontal, vertical, main and minor diagonal pixel values from current pixel values respectively and then thresholded with a predefined threshold T. The GLCMs of edge images along the four directions serve as features for image splicing detection. Boosting feature selection is applied to select optimal features and Support Vector Machine (SVM) is utilized as classifier in our approach. The effectiveness of the proposed method has been demonstrated by our experimental results. \textcopyright{}2009 IEEE.},
  copyright = {All rights reserved},
  isbn = {978-1-4244-5654-3},
  keywords = {Boosting feature selection,Co-occurrence matrix,Image chroma,Image splicing detection,SVM}
}

@incollection{Wang2009a,
  title = {A Survey of Passive Image Tampering Detection},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2009},
  volume = {5703 LNCS},
  pages = {308--322},
  publisher = {{Springer}},
  issn = {03029743},
  doi = {10.1007/978-3-642-03688-0_27},
  abstract = {Digital images can be easily tampered with image editing tools. The detection of tampering operations is of great importance. Passive digital image tampering detection aims at verifying the authenticity of digital images without any a prior knowledge on the original images. There are various methods proposed in this filed in recent years. In this paper, we present an overview of these methods in three levels, that is low level, middle level, and high level in semantic sense. The main ideas of the proposed approaches at each level are described in detail, and some comments are given. \textcopyright{} 2009 Springer.},
  copyright = {All rights reserved},
  isbn = {3-642-03687-2},
  keywords = {Image model,Image tampering,Image tampering detection,Imaging process}
}

@inproceedings{Wang2010,
  title = {Image Tampering Detection Based on Stationary Distribution of {{Markov}} Chain},
  booktitle = {Proceedings - International Conference on Image Processing, {{ICIP}}},
  author = {Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2010},
  month = sep,
  pages = {2101--2104},
  publisher = {{IEEE}},
  issn = {15224880},
  doi = {10.1109/ICIP.2010.5652660},
  abstract = {In this paper, we propose a passive image tampering detection method based on modeling edge information. We model the edge image of image chroma component as a finite-state Markov chain and extract low dimensional feature vector from its stationary distribution for tampering detection. The support vector machine (SVM) is utilized as classifier to evaluate the effectiveness of the proposed algorithm. The experimental results in a large scale of evaluation database illustrates that our proposed method is promising. \textcopyright{} 2010 IEEE.},
  copyright = {All rights reserved},
  isbn = {978-1-4244-7994-8},
  keywords = {Image chroma,Markov chain,Stationary distribution,Tampering detection}
}

@incollection{Wang2011a,
  title = {Tampered Region Localization of Digital Color Images Based on {{JPEG}} Compression Noise},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2011},
  month = dec,
  volume = {6526 LNCS},
  pages = {120--133},
  issn = {16113349},
  doi = {10.1007/978-3-642-18405-5_10},
  abstract = {With the availability of various digital image edit tools, seeing is no longer believing. In this paper, we focus on tampered region localization for image forensics. We propose an algorithm which can locate tampered region(s) in a lossless compressed tampered image when its unchanged region is output of JPEG decompressor. We find the tampered region and the unchanged region have different responses for JPEG compression. The tampered region has stronger high frequency quantization noise than the unchanged region. We employ PCA to separate different spatial frequencies quantization noises, i.e. low, medium and high frequency quantization noise, and extract high frequency quantization noise for tampered region localization. Post-processing is involved to get final localization result. The experimental results prove the effectiveness of our proposed method.},
  copyright = {All rights reserved},
  isbn = {978-3-642-18404-8},
  keywords = {Image forensics,JPEG compression noise,PCA,Tampered region localization}
}

@inproceedings{Wang2011b,
  title = {Exploring {{DCT}} Coefficient Quantization Effect for Image Tampering Localization},
  booktitle = {2011 {{IEEE}} International Workshop on Information Forensics and Security, {{WIFS}} 2011},
  author = {Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2011},
  month = nov,
  pages = {1--6},
  publisher = {{IEEE}},
  doi = {10.1109/WIFS.2011.6123129},
  abstract = {In this paper, we focus on image tampering detection and tampered region localization. We find that the probability distributions of the DCT coefficients of a JEPG image will be influenced by tampering operation. Hence, we model the distributions of AC DCT coefficients of JPEG image and detect the tampered region from the unchanged region by using their different distributions. Based on an assumption of Laplacian distribution of unquantized AC DCT coefficients, Laplacian Mixture Model (LMM) is employed to model the quantized AC DCT coefficient distribution of a suspicious JPEG image. With the help of Expectation Maximization (EM) algorithm, the probability of an 8 x 8 block being tampered can be estimated; and then, a sophisticated image segmentation method, graph cut, is applied to determine the tampered region. Extensive experimental results on large scale databases prove the effectiveness of our proposed method which is suitable for different tampered region sizes at all levels including pixel, region and image level. \textcopyright{} 2011 IEEE.},
  copyright = {All rights reserved},
  isbn = {978-1-4577-1017-9}
}

@article{Wang2014,
  title = {Exploring {{DCT}} Coefficient Quantization Effects for Local Tampering Detection},
  author = {Wang, Wei and Dong, Jing and Tan, Tieniu},
  year = {2014},
  month = oct,
  volume = {9},
  pages = {1653--1666},
  publisher = {{IEEE}},
  issn = {15566013},
  doi = {10.1109/TIFS.2014.2345479},
  abstract = {In this paper, we focus on local image tampering detection. For a JPEG image, the probability distributions of its DCT coefficients will be disturbed by tampering operation. The tampered region and the unchanged region have different distributions, which is an important clue for locating tampering. Based on the assumption of Laplacian distribution of unquantized ac DCT coefficients, these two distributions as well as the size of tampered region can be estimated so that the probability of each DCT block being tampered is obtained. More accurate localization results could be got when we consider the prior knowledge of common tampered regions. We also design three kinds of features that can distinguish truly tampered regions from the false ones to reduce false alarm. For a tampered image which is saved in lossless compressed format, we also propose the specialized approach, which employs the quantization noise of high-frequency DCT coefficient, to improve the tampering localization performance. Extensive experiments on large scale databases prove the effectiveness of our proposed method and demonstrate that our method is suitable for locating tampered regions with different scales.},
  copyright = {All rights reserved},
  journal = {IEEE Transactions on Information Forensics and Security},
  keywords = {double quantization,graph cut,Image forensics,local tampering detection},
  number = {10}
}

@incollection{Wang2014b,
  title = {Improved Robust Watermarking Based on Rational Dither Modulation},
  booktitle = {Communications in Computer and Information Science},
  author = {Wang, Zairan and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2014},
  volume = {437},
  pages = {305--314},
  issn = {18650929},
  doi = {10.1007/978-3-662-45498-5_34},
  abstract = {Rational dither modulation (RDM) watermarking was presented to resist amplitude scaling attack. This property is achieved by quantizing the ratio of consecutive samples instead of samples themselves. In this paper, we improve the performance of basic RDM watermarking to resist more types of watermarking attacks. We improve the robustness of our modified RDM watermarking by the following three aspects: 1) The quantization step size is increased by modifying two coefficients instead of only one coefficient in the basic RDM method, 2) Several modification rules are defined to reduce embedding distortion, and 3) The coefficients with larger magnitudes in the lowest sub-band in DWT domain are selected to embed watermark. A variety of attacks are implemented to evaluate the performance of our method. Experimental results demonstrate that our method outperforms the basic RDM method and two state-of-the-art watermarking methods over a wide range of attacks and it also has good imperceptibility.},
  copyright = {All rights reserved},
  isbn = {978-3-662-45497-8},
  keywords = {Amplitude scaling attack,RDM,Watermarking}
}

@inproceedings{Wang2014c,
  title = {An Effective Watermarking Method against Valumetric Distortions},
  booktitle = {2014 {{IEEE}} International Conference on Image Processing, {{ICIP}} 2014},
  author = {Wang, Zairan and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2014},
  month = oct,
  pages = {5487--5491},
  publisher = {{IEEE}},
  doi = {10.1109/ICIP.2014.7026110},
  abstract = {Most of the quantization based watermarking algorithms are very sensitive to valumetric distortions, while these distortions are regarded as common processing in audio/video analysis. In recent years, watermarking methods which can resist this kind of distortions have attracted a lot of interests. But still many proposed methods can only deal with one certain kind of valumetric distortion as amplitude scaling, and fail in other kinds of valumetric distortions like constant change attack or gamma correction. In this paper, we propose a very simple method to tackle all the three kinds of valumetric distortions. A constant change invariant domain is first constructed by spread transform, in which the watermark is embedded using a certain amplitude scaling invariant based watermarking scheme. Several typical watermarking methods and attacks have been implemented in our experiments to demonstrate the effectiveness of the proposed method.},
  copyright = {All rights reserved},
  isbn = {978-1-4799-5751-4},
  keywords = {amplitude scaling,QIM,valumetric distortions,watermarking}
}

@incollection{Wang2015,
  title = {Effects of Fragile and Semi-Fragile Watermarking on Iris Recognition System},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Wang, Zairan and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2015},
  volume = {9023},
  pages = {174--186},
  issn = {16113349},
  doi = {10.1007/978-3-319-19321-2_13},
  abstract = {Security is an important issue in biometric recognition systems. In recent years, many researchers proposed to use watermarking to improve the security of biometric systems, but some people concern whether the embedded watermarks will influence recognition results. In this paper, we investigate the effects of several fragile and semi-fragile watermarking methods on the iris recognition performance. Experimental results demonstrate that, even images are fully embedded, fragile watermarking methods nearly have no effects on the recognition performance, while semi-fragile watermarking methods which embed watermark in the visually important components of images have larger effects on the recognition performance than the semi-fragile watermarking methods that embed watermark in the visually unimportant components of images. And embedding parameters, such as embedding strength and watermark length, also have some influences on the recognition results.},
  copyright = {All rights reserved},
  keywords = {Fragile watermarking,Iris recognition systems,Semi-fragile watermarking}
}

@article{Wang2017,
  title = {Quantization Based Watermarking Methods against Valumetric Distortions},
  author = {Wang, Zai Ran and Dong, Jing and Wang, Wei},
  year = {2017},
  month = dec,
  volume = {14},
  pages = {672--685},
  publisher = {{Institute of Automation, Chinese Academy of Sciences}},
  issn = {17518520},
  doi = {10.1007/s11633-016-1010-6},
  abstract = {Most of the quantization based watermarking algorithms are very sensitive to valumetric distortions, while these distortions are regarded as common processing in audio/video analysis. In recent years, watermarking methods which can resist this kind of distortions have attracted a lot of interests. But still many proposed methods can only deal with one certain kind of valumetric distortion such as amplitude scaling attack, and fail in other kinds of valumetric distortions like constant change attack, gamma correction or contrast stretching. In this paper, we propose a simple but effective method to tackle all the three kinds of valumetric distortions. This algorithm constructs an invariant domain first by spread transform which satisfies certain constraints. Then an amplitude scale invariant watermarking scheme is applied on the constructed domain. The validity of the approach has been confirmed by applying the watermarking scheme to Gaussian host data and real images. Experimental results confirm its intrinsic invariance against amplitude scaling, constant change attack and robustness improvement against nonlinear valumetric distortions.},
  copyright = {All rights reserved},
  journal = {International Journal of Automation and Computing},
  keywords = {amplitude scaling,constant change attack,Quantization index modulation (QIM),valumetric distortions,watermarking},
  number = {6}
}

@article{Wang2018,
  title = {Deep Steganalysis: {{End}}-to-End Learning with Supervisory Information beyond Class Labels},
  author = {Wang, Wei and Dong, Jing and Qian, Yinlong and Tan, Tieniu},
  year = {2018},
  month = jun,
  abstract = {Recently, deep learning has shown its power in steganalysis. However, the proposed deep models have been often learned from pre-calculated noise residuals with fixed high-pass filters rather than from raw images. In this paper, we propose a new end-to-end learning framework that can learn steganalytic features directly from pixels. In the meantime, the high-pass filters are also automatically learned. Besides class labels, we make use of additional pixel level supervision of cover-stego image pair to jointly and iteratively train the proposed network which consists of a residual calculation network and a steganalysis network. The experimental results prove the effectiveness of the proposed architecture.},
  archivePrefix = {arXiv},
  arxivid = {1806.10443},
  copyright = {All rights reserved},
  eprint = {1806.10443},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1806.10443}
}

@article{Wu2017,
  title = {A Graph-Theoretic Model to Steganography on Social Networks},
  author = {Wu, Hanzhou and Wang, Wei and Dong, Jing and Xiong, Yiliang and Wang, Hongxia},
  year = {2017},
  month = dec,
  abstract = {Steganography aims to conceal the very fact that the communication takes place, by embedding a message into a digit object such as image without introducing noticeable artifacts. A number of steganographic systems have been developed in past years, most of which, however, are confined to the laboratory conditions where the real-world use of steganography are rarely concerned. In this paper, we introduce an alternative perspective to steganography. A graph-theoretic model to steganography on social networks is presented to analyze real-world steganographic scenarios. In the graph, steganographic participants are corresponding to the vertices with meaningless unique identifiers. Each edge allows the two vertices to communicate with each other by any steganographic algorithm. Meanwhile, the edges are associated with weights to quantize the corresponding communication risk (or say cost). The optimization task is to minimize the overall risk, which is modeled as additive over the social network. We analyze different scenarios on a social network, and provide the suited solutions to the corresponding optimization tasks. We prove that a multiplicative probabilistic graph is equivalent to an additive weighted graph. From the viewpoint of an attacker, he may hope to detect suspicious communication channels, the data encoder(s) and the data decoder(s). We present limited detection analysis to steganographic communication on a network.},
  archivePrefix = {arXiv},
  arxivid = {1712.03621},
  copyright = {All rights reserved},
  eprint = {1712.03621},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1712.03621}
}

@incollection{Wu2018,
  title = {Reversible Embedding to Covers Full of Boundaries},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Wu, Hanzhou and Wang, Wei and Dong, Jing and Chen, Yanli and Wang, Hongxia and Wu, Songyang},
  year = {2018},
  volume = {11066 LNCS},
  pages = {404--415},
  issn = {16113349},
  doi = {10.1007/978-3-030-00015-8_35},
  abstract = {In reversible data embedding, to avoid overflow and underflow problem, before data embedding, boundary pixels are recorded as side information, which may be losslessly compressed. The existing algorithms often assume that a natural image has few boundary pixels so that the size of side information could be rather small. Accordingly, a relatively high pure payload could be achieved. However, there actually may exist a lot of boundary pixels in a natural image, implying that, the size of side information could be very large. Thus, when to directly use the existing algorithms, the pure embedding capacity may be not sufficient. In order to address this important problem, in this paper, we present a new and efficient framework to reversible data embedding in images that have lots of boundary pixels. The core idea is to losslessly preprocess boundary pixels so that it can significantly reduce the side information. We conduct extensive experiments to show the superiority and applicability of our work.},
  archivePrefix = {arXiv},
  arxivid = {1801.04752},
  copyright = {All rights reserved},
  eprint = {1801.04752},
  eprinttype = {arxiv},
  isbn = {978-3-030-00014-1},
  keywords = {Histogram shifting,Location map,Prediction,Reversible data hiding,Side information,Watermarking}
}

@inproceedings{Wu2018a,
  title = {Ensemble Reversible Data Hiding},
  booktitle = {Proceedings - International Conference on Pattern Recognition},
  author = {Wu, Hanzhou and Wang, Wei and Dong, Jing and Wang, Hongxia},
  year = {2018},
  month = aug,
  volume = {2018-Augus},
  pages = {2676--2681},
  publisher = {{IEEE}},
  address = {{Beijing}},
  issn = {10514651},
  doi = {10.1109/ICPR.2018.8545536},
  abstract = {The conventional reversible data hiding (RDH) algorithms often consider the host as a whole to embed a secret payload. In order to achieve satisfactory rate-distortion performance, the secret bits are embedded into the noise-like component of the host such as prediction errors. From the rate-distortion optimization view, it may be not optimal since the data embedding units use the identical parameters. This motivates us to present a segmented data embedding strategy for efficient RDH in this paper, in which the raw host could be partitioned into multiple subhosts such that each one can freely optimize and use the data embedding parameters. Moreover, it enables us to apply different RDH algorithms within different subhosts, which is defined as ensemble. Notice that, the ensemble defined here is different from that in machine learning. Accordingly, the conventional operation corresponds to a special case of the proposed work. Since it is a general strategy, we combine some state-of-the-art algorithms to construct a new system using the proposed embedding strategy to evaluate the rate-distortion performance. Experimental results have shown that, the ensemble RDH system could outperform the original versions in most cases, which has shown the superiority and applicability.},
  copyright = {All rights reserved},
  isbn = {978-1-5386-3788-3},
  keywords = {ensemble,fragile,rate-distortion optimization,Reversible data hiding,segmented,watermarking}
}

@article{Wu2018b,
  title = {The Cut and Dominating Set Problem in a Steganographer Network},
  author = {Wu, Hanzhou and Wang, Wei and Dong, Jing and Wang, Hongxia and Xiong, Lizhi},
  year = {2018},
  month = feb,
  abstract = {A steganographer network corresponds to a graphic structure that the involved vertices (or called nodes) denote social entities such as the data encoders and data decoders, and the associated edges represent any real communicable channels or other social links that could be utilized for steganography. Unlike traditional steganographic algorithms, a steganographer network models steganographic communication by an abstract way such that the concerned underlying characteristics of steganography are quantized as analyzable parameters in the network. In this paper, we will analyze two problems in a steganographer network. The first problem is a passive attack to a steganographer network where a network monitor has collected a list of suspicious vertices corresponding to the data encoders or decoders. The network monitor expects to break (disconnect) the steganographic communication down between the suspicious vertices while keeping the cost as low as possible. The second one relates to determining a set of vertices corresponding to the data encoders (senders) such that all vertices can share a message by neighbors. We point that, the two problems are equivalent to the minimum cut problem and the minimum-weight dominating set problem.},
  archivePrefix = {arXiv},
  arxivid = {1802.09333},
  copyright = {All rights reserved},
  eprint = {1802.09333},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1802.09333}
}

@article{Wu2019,
  title = {New Graph-Theoretic Approach to Social Steganography},
  author = {Wu, Hanzhou and Wang, Wei and Dong, Jing and Wang, Hongxia},
  year = {2019},
  month = jan,
  volume = {2019},
  pages = {539-1-539-7},
  publisher = {{Society for Imaging Science and Technology}},
  issn = {2470-1173},
  doi = {10.2352/issn.2470-1173.2019.5.mwsf-539},
  abstract = {In this paper, we introduce a new and novel graph-theoretic steganographic approach applicable to online social networking services (SNSs). The proposed approach translates a secret message to be embedded as an undirected graph called messagegraph, the structural information of which is concealed within a new directed graph. The new directed graph is released in a SNS platform by producing a sequence of ordered multiple-user interaction events. To secure communication, we propose to split a specific vertex to multiple copies and insert new vertices and edges to the directed graph. A receiver is able to reconstruct the directed graph from observations. Both the message-graph and the secret message can be orderly retrieved without error. It is probably the first work deeply focusing on the practical design of interaction based steganography using graph-theoretic approach.},
  copyright = {All rights reserved},
  journal = {Electronic Imaging},
  keywords = {Graph theory,Social network,Steganography},
  number = {5}
}

@inproceedings{Xu2013,
  title = {Video Steganalysis Based on the Constraints of Motion Vectors},
  booktitle = {2013 {{IEEE}} International Conference on Image Processing, {{ICIP}} 2013 - Proceedings},
  author = {Xu, Xikai and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2013},
  month = sep,
  pages = {4422--4426},
  publisher = {{IEEE}},
  doi = {10.1109/ICIP.2013.6738911},
  abstract = {In this paper, we focus on detecting data hiding in motion vectors of compressed video and propose a new steganalytic algorithm based on the mutual constraints of motion vectors. The constraints of motion vectors from multiple frames are analyzed and formulized by three functions, then statistical features are extracted based on these functions. Moreover, we also incorporate calibration method to improve the detection accuracy. Experimental results demonstrate that the proposed method can effectively attack typical motion-vector-based video steganography. \textcopyright{} 2013 IEEE.},
  copyright = {All rights reserved},
  isbn = {978-1-4799-2341-0},
  keywords = {data hiding,motion vector,mutual constraints,stegnography,Video steganalysis}
}

@inproceedings{Xu2015,
  title = {Robust Steganalysis Based on Training Set Construction and Ensemble Classifiers Weighting},
  booktitle = {Proceedings - International Conference on Image Processing, {{ICIP}}},
  author = {Xu, Xikai and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2015},
  month = sep,
  volume = {2015-Decem},
  pages = {1498--1502},
  publisher = {{IEEE}},
  issn = {15224880},
  doi = {10.1109/ICIP.2015.7351050},
  abstract = {The cover source mismatch problem in steganalysis is a serious problem which keeps current steganalysis from practical use. It is mainly because of the high intra-class variation of cover and stego samples in the feature space, since current ste-ganalytic features are inevitably affected much by the image content, size, quality and many other factors. Small training set often reflects only part of the real data distribution, hence the classifier (steganalyzer) may be undertrained and lack of robustness. In this paper, we propose a scheme to efficiently construct large representative training set for steganalysis. We also scheme out weighted ensemble classifiers which can be adaptive to testing data. Experimental results show that our method can improve the performance and robustness of ste-ganalysis under high intra-class variation.},
  copyright = {All rights reserved},
  isbn = {978-1-4799-8339-1},
  keywords = {ensemble classifiers,sample selection,steganalysis,Steganography}
}

@inproceedings{Xu2015a,
  title = {Local Correlation Pattern for Image Steganalysis},
  booktitle = {2015 {{IEEE}} China Summit and International Conference on Signal and Information Processing, {{ChinaSIP}} 2015 - Proceedings},
  author = {Xu, Xikai and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2015},
  month = jul,
  pages = {468--472},
  publisher = {{IEEE}},
  doi = {10.1109/ChinaSIP.2015.7230446},
  abstract = {Correlation of pixels is the most important information used for image steganalysis. Current methods often consider some special types of relationships among neighboring pixels. In this paper, we propose a general descriptor to consider the correlation of pixels comprehensively. We consider the correlation of pixels in an adjacency pattern as a local correlation pattern (LCP). The LCP descriptor is proposed to embrace different local correlation patterns and represent each pattern by mapping the relative values of pixels in the pattern to a numerical value. Then, histograms of LCP values are taken as features for steganalysis. The LCP descriptor also can be used for describing the correlation of elements in the residual image obtained by image filtering. Experiments show that our constructed feature set based on the LCP descriptor outperforms a state-of-The-Art method on detecting three popular steganographic algorithms.},
  copyright = {All rights reserved},
  isbn = {978-1-4799-1948-2},
  keywords = {LCP,local correlation,steganalysis,Steganography}
}

@incollection{Xu2016,
  title = {An Adaptive Ensemble Classifier for Steganalysis Based on Dynamic Weighted Fusion},
  booktitle = {Lecture Notes in Electrical Engineering},
  author = {Xu, Xikai and Dong, Jing and Wang, Wei and Tan, Tieniu},
  year = {2016},
  volume = {386},
  pages = {639--647},
  issn = {18761119},
  doi = {10.1007/978-3-662-49831-6_65},
  abstract = {Recently, ensemble classifier is predominantly used for steganalysis of digital media, due to its efficiency when working with high-dimensional feature sets and large databases. While fusing the decisions of many weak base classifiers, the majority voting rule is often used, which has the disadvantage that all the classifiers have the same authority regardless of their individual classification abilities. In this paper, we propose a new dynamic weighted fusion method for steganalysis which can be adaptive to input testing samples. For each testing sample, the weight of each base classifier is dynamically assigned according to the distance between the testing sample and the classifier. Experimental results show that the proposed method is able to increase steganalysis performance.},
  copyright = {All rights reserved},
  isbn = {978-3-662-49829-3},
  keywords = {Dynamic weighted fusion,Ensemble classifiers,Majority voting,Steganalysis,Steganography}
}

@incollection{Xuan2019,
  title = {On the Generalization of {{GAN}} Image Forensics},
  booktitle = {Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  author = {Xuan, Xinsheng and Peng, Bo and Wang, Wei and Dong, Jing},
  year = {2019},
  month = feb,
  volume = {11818 LNCS},
  pages = {134--141},
  issn = {16113349},
  doi = {10.1007/978-3-030-31456-9_15},
  abstract = {Recently GAN generated face images are more and more realistic with high-quality, even hard for human eyes to detect. On the other hand, the forensics community keeps on developing methods to detect these generated fake images and try to ensure the credibility of visual contents. Although researchers have developed some methods to detect generated images, few of them explore the important problem of generalization ability of forensics model. As new types of GANs are emerging fast, the generalization ability of forensics models to detect new types of GAN images is absolutely an essential research topic, which is also very challenging. In this paper, we explore this problem and propose to use preprocessed images to train a forensic CNN model. By applying similar image level preprocessing to both real and fake images, unstable low level noise cues are destroyed, and the forensics model is forced to learn more intrinsic features to classify the generated and real face images. Our experimental results also prove the effectiveness of the proposed method.},
  archivePrefix = {arXiv},
  arxivid = {1902.11153},
  copyright = {All rights reserved},
  eprint = {1902.11153},
  eprinttype = {arxiv},
  isbn = {978-3-030-31455-2},
  keywords = {Fake image detection,GAN,Image forensics}
}

@incollection{Ye2017,
  title = {Image Forgery Detection Based on Semantic Image Understanding},
  booktitle = {Communications in Computer and Information Science},
  author = {Ye, Kui and Dong, Jing and Wang, Wei and Xu, Jindong and Tan, Tieniu},
  year = {2017},
  volume = {771},
  pages = {472--481},
  issn = {18650929},
  doi = {10.1007/978-981-10-7299-4_39},
  abstract = {Image forensics has been focusing on low-level visual features, paying little attention to high-level semantic information of the image. In this work, we propose the framework for image forgery detection based on high-level semantics with three components of image understanding module, the normal rule bank (NR) holding semantic rules that comply with our common sense, and the abnormal rule bank (AR) holding semantic rules that don't. Ke et al. [1] also proposed a similar framework, but ours has following advantages. Firstly, image understanding module is integrated by a dense image caption model, with no need for human intervention and more hierarchical features. secondly, our proposed framework can generate thousands of semantic rules automatically for NR. Thirdly, besides NR, we also propose to construct AR. In this way, not only can we frame image forgery detection as anomaly detection with NR, but also as recognition problem with AR. The experimental results demonstrate our framework is effective and performs better.},
  copyright = {All rights reserved},
  isbn = {978-981-10-7298-7},
  keywords = {AR,Deep learning,Image forensics,Image understanding module,NR}
}

@inproceedings{Ye2019,
  title = {Feature Pyramid Deep Matching and Localization Network for Image Forensics},
  booktitle = {2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, {{APSIPA ASC}} 2018 - Proceedings},
  author = {Ye, Kui and Dong, Jing and Wang, Wei and Peng, Bo and Tan, Tieniu},
  year = {2019},
  month = nov,
  pages = {1796--1802},
  publisher = {{IEEE}},
  doi = {10.23919/APSIPA.2018.8659464},
  abstract = {To advance the state of the art of image forensics technologies, a new formulation of splicing localization is proposed, which aims to obtain the masks for both the query and donor images for a pair of query(probe) image and potential donor image if a region of the donor image was spliced into the probe. The former Deep Matching and Validation Network(DMVN) addresses the problem with a novel end-to-end learning based solution. Inheriting the deep dense matching layer, we propose Feature Pyramid Deep Matching and Localization Network(FPLN), whose contributions are three folds. Firstly, instead of using just one feature map as in DMVN, FPLN utilizes a pyramid of feature maps with different resolutions w.r.t. the input image to achieve better localization performance, especially for small objects. Secondly, we add a fusion layer that fuses together all the features after deep dense matching layer, which not only takes full advantage of the correlation information between those features, but is also able to integrate two pathways in DMVN into just one simple pathway, simplifying the subsequent architecture. Lastly, we employ focal loss to address the imbalance problem, as the foreground area is usually much smaller than the background area. The experiments demonstrate the superior performance of our proposed method in detection accuracy and in localizing small tempered regions.},
  copyright = {All rights reserved},
  isbn = {978-988-14768-5-2}
}


